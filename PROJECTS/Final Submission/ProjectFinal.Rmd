---
title: "MATH 490 Stock Data Final Project"
author: "Mitchell Krystofiak"
date: "12/16/2021"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Founded in 2003, Tesla aims to accelerate the world's transition in to sustainable energy by building better, faster, and more affordable electric cars than gasoline cars. Tesla also focuses on producing clean energy power through the installation of solar panels and energy solutions such as Powerwall, PowerPack and Solar Roof. Tesla has continued, with the leadership of CEO Elon Musk, to release cutting edge electric vehicle designs, including the first ever all-electric sedan. They have also continued to prove thath they can produce all-electric vehicles while keeping up with safety protocols, reliability ratings, battery efficiency and affordability.

## Tesla Stock Information

On June 29, 2010, Tesla Motors launched its initial public offering on NASDAQ by issuing 13,300,000 shares of common stock at a price of \$17.00 per share. As of December 12, 2021, Tesla is now worth \$1017.03 per share, with a 52 week low of \$539.49 and a 52 week high of \$1243.49 per share.

```{r table1, echo=FALSE}
library(flextable)
tsla <- read.csv("./TSLA.csv")

ft <- flextable(tail(tsla))
ft <- set_caption(ft, caption='Tesla Stock Data')
ft <- theme_vader(ft)
ft <- add_footer_lines(ft, "Most recent TSLA stock data from Decemeber 12, 2021.")
ft <- color(ft, part='footer', color='#666666')
ft
```

## Project Goals

One of the major goals of this project is to better understand technical analysis and get a look into another popular indicator: the Relative Strength Index (RSI). The RSI is a momentum indicator that measures the magnitude of recent price changes to evaluate overbought or oversold conditions in the price of a stock. The RSI is displayed as an oscillator between 0 and 100. It was developed by J. Welles Wilder Jr. and introduced in 1978. Traditionally, RSI values greater than or equal to 70 indicate that a stock is becoming overbought or overvalued, and may be primed for a trend reversal or pullback. An RSI value less than or equal to 30 usually indicates that a stock is oversold or undervalued.

In addition to the RSI, we can also look at the On Balance Volume (OBV) indicator. This is another momentum indicator that uses volume flow to predict changes in the stock price. It was developed by Joseph Granville in 1963. Since this is more of a leading indicator, it is hard to determine a buy signal off of just this, and no technical analysis is included.

The last goal of this project is to examine basic rating methods against other stocks. In other words, how can we rank a stock versus another stock to determine what our likelihood of success is if we invest in one company over another? To use the Markov Method, Massey Method, or the Colley method, there needs to be some sort of win or lose definition, so we can say "stock A lost to stock B" and we can use these methods.

## RSI Computation and Analysis

To calculate the RSI, we need to calculate the change in closing price between days, the average gain, the average loss, and the Relative Strength. For the change, we just subtract yesterdays closing price from todays closing price for all of Tesla's data. For the average gain and loss, we average 14 days of gains and losses. Then, we compute our RS by dividing the average gains over the average losses. Finally to compute the RSI:
$$RSI = 100 - \frac{100}{1+RS} $$
If the average loss is 0, our RSI is 100.
```{r RSI, echo = FALSE}
#Fix dates

tsla$Date <- as.Date(tsla$Date, format="%Y-%m-%d")

#Select out returns

tslats <- data.frame(tsla[,c(1,5)])
tslada <- tsla[,1]
tslaClose <- tsla[,5]

#Compute Change in Close prices.

change <- c()
imax <- length(tslaClose)

for (i in 1:(imax-1))
{
  change[i] <- tslaClose[i+1] - tslaClose[i]
}

# Determine if gain or loss.

gain <- c()
loss <- c()

for (i in 1:(imax-1))
{
  if (change[i] > 0)
  {
    gain[i] <- change[i]
    loss[i] <- 0
  }
  else
  {
    loss[i] <- abs(change[i])
    gain[i] <- 0
  }
}

#Compute Average Gain and Average Loss over 14 day period.

avgGain <- c()
avgLoss <- c()

for (i in 14:(imax-1))
{
  jmin <- (i - 13)
  avgGain[i] <- 0
  avgLoss[i] <- 0
  for (j in jmin:i)
  {
    avgGain[i] <- avgGain[i] + gain[j]
    avgLoss[i] <- avgLoss[i] + loss[j]
  }
  avgGain[i] <- avgGain[i]/14
  avgLoss[i] <- avgLoss[i]/14
}

# Compute Relative Strength = AvgGain/AvgLoss

RS <- c()

for (i in 1:(imax-1))
{
  RS[i] <- avgGain[i]/avgLoss[i]
}

#Compute Relative Strength Index
# RSI = if (avgloss = 0 -> 100, else 100 - (100/(1+RS)))

RSI <- c()

for (i in 14:(imax-1))
{
  if (avgLoss[i] == 0)
  {
    RSI[i] <- 100
  }
  else
  {
    RSI[i] <- (100 - (100/(1+RS[i])))
  }
}

#Plot the RSI

val <- 100
plot(tslada[1:(imax-1)], tslaClose[1:(imax-1)],
     type ='l',
     main='Closing Price (Alltime)',
     xlab='Date',
     ylab='Price')
plot(tslada[1:(imax-1)], RSI[1:(imax-1)], 
     type='l',
     main="RSI (Alltime)",
     xlab="Date",
     ylab="RSI",
     col='black')
abline(h=30, col='red')
abline(h=70, col='red')

plot(tslada[1:(imax-val-1)], tslaClose[1:(imax-val-1)],
     type ='l',
     main='Closing Price (Zoomed In)',
     xlab='Date',
     ylab='Price')
plot(tslada[(imax-val-1):(imax-1)], RSI[(imax-val-1):(imax-1)], 
     type='l',
     main="RSI (Zoomed In)",
     xlab="Date",
     ylab="RSI",
     col='black')
abline(h=30, col='red')
abline(h=40, col='red')
abline(h=70, col='red')
```

Now that we have our RSI calculated and plotted alongside the closing price, we can start discussing a buy signal! Though this is not an exact science, and many different tactics have been used, a common indicator to buy is when the RSI falls below 30. This could signify that the stock is oversold and undervalued, making it prime for a trend reversal upwards. We will set this as our buy signal, and then we will begin our thorough technical analysis. Below are the recorded prices after a RSI Crossover (RSIC). We also follow the Non RSIC.

```{r BuyRSI, echo=FALSE}
icmax <- (imax-1)
count <- 0
countNot <- 0

tsla1ret <- c()
tsla5ret <- c()
tsla10ret <- c()
tsla15ret <- c()
tsla20ret <- c()

tslaNot1ret <- c()
tslaNot5ret <- c()
tslaNot10ret <- c()
tslaNot15ret <- c()
tslaNot20ret <- c()

tslaU1 <- c()
tslaU5 <- c()
tslaU10 <- c()
tslaU15 <- c()
tslaU20 <- c()

tslaRSIda <- as.Date(c())
tslaRSINotda <- as.Date(c())

for (i in 21:icmax)
{
  if (RSI[i-1] > 30 && RSI[i] <= 30)
  {
    count <- count + 1
    tsla1ret[count] <- ((tslaClose[i+1] - tslaClose[i])/tslaClose[i])*100
    tsla5ret[count] <- ((tslaClose[i+5] - tslaClose[i])/tslaClose[i])*100
    tsla10ret[count] <- ((tslaClose[i+10] - tslaClose[i])/tslaClose[i])*100
    tsla15ret[count] <- ((tslaClose[i+15] - tslaClose[i])/tslaClose[i])*100
    tsla20ret[count] <- ((tslaClose[i+20] - tslaClose[i])/tslaClose[i])*100
    tslaRSIda[count] <- tslada[i]
  }
  else
  {
    countNot <- countNot + 1
    tslaNot1ret[countNot] <- ((tslaClose[i+1] - tslaClose[i])/tslaClose[i])*100
    tslaNot5ret[countNot] <- ((tslaClose[i+5] - tslaClose[i])/tslaClose[i])*100
    tslaNot10ret[countNot] <- ((tslaClose[i+10] - tslaClose[i])/tslaClose[i])*100
    tslaNot15ret[countNot] <- ((tslaClose[i+15] - tslaClose[i])/tslaClose[i])*100
    tslaNot20ret[countNot] <- ((tslaClose[i+20] - tslaClose[i])/tslaClose[i])*100
    tslaRSINotda[countNot] <- tslada[i]
  }
}

for (i in 1:icmax)
{
  tslaU1[i] <- ((tslaClose[i+1] - tslaClose[i])/tslaClose[i])*100
  tslaU5[i] <- ((tslaClose[i+5] - tslaClose[i])/tslaClose[i])*100
  tslaU10[i] <- ((tslaClose[i+10] - tslaClose[i])/tslaClose[i])*100
  tslaU15[i] <- ((tslaClose[i+15] - tslaClose[i])/tslaClose[i])*100
  tslaU20[i] <- ((tslaClose[i+20] - tslaClose[i])/tslaClose[i])*100
}

plot(tslaRSIda, tsla1ret,
     main='1 Day After RSIC',
     xlab='Dates',
     ylab='Price')
abline(0,0)
plot(tslaRSIda, tsla5ret,
     main='5 Days After RSIC',
     xlab='Dates',
     ylab='Price')
abline(0,0)
plot(tslaRSIda, tsla10ret,
     main='10 Days After RSIC',
     xlab='Dates',
     ylab='Price')
abline(0,0)
plot(tslaRSIda, tsla15ret,
     main='15 Days After RSIC',
     xlab='Dates',
     ylab='Price')
abline(0,0)
plot(tslaRSIda, tsla20ret,
     main='20 Days After RSIC',
     xlab='Dates',
     ylab='Price')
abline(0,0)
```

Next, we will compute the summary statistics, boxplots, histograms and qqplots of each of the days after results. This will give us more insight into the normality of the data, and possibly allow us to detect whether or not we have statistical differences in results early on.

```{r summaryStats, echo = FALSE}
Stats <- c('Min','Q1','Q2','Mean','Q3','Max')
U1 <- as.vector(summary(tslaU1)[1:6])
Ret1 <- as.vector(summary(tsla1ret)[1:6])
NRet1 <- as.vector(summary(tslaNot1ret)[1:6])
UData <- data.frame(Stats, U1, Ret1, NRet1)
ft <- flextable(UData)
ft <- theme_vader(ft)
ft

U5 <- as.vector(summary(tslaU5)[1:6])
Ret5 <- as.vector(summary(tsla5ret)[1:6])
NRet5 <- as.vector(summary(tslaNot5ret)[1:6])
UData <- data.frame(Stats, U5, Ret5, NRet5)
ft <- flextable(UData)
ft <- theme_vader(ft)
ft

U10 <- as.vector(summary(tslaU10)[1:6])
Ret10 <- as.vector(summary(tsla10ret)[1:6])
NRet10 <- as.vector(summary(tslaNot10ret)[1:6])
UData <- data.frame(Stats, U10, Ret10, NRet10)
ft <- flextable(UData)
ft <- theme_vader(ft)
ft

U15 <- as.vector(summary(tslaU15)[1:6])
Ret15 <- as.vector(summary(tsla15ret)[1:6])
NRet15 <- as.vector(summary(tslaNot15ret)[1:6])
UData <- data.frame(Stats, U15, Ret15, NRet15)
ft <- flextable(UData)
ft <- theme_vader(ft)
ft

U20 <- as.vector(summary(tslaU20)[1:6])
Ret20 <- as.vector(summary(tsla20ret)[1:6])
NRet20 <- as.vector(summary(tslaNot20ret)[1:6])
UData <- data.frame(Stats, U20, Ret20, NRet20)
ft <- flextable(UData)
ft <- theme_vader(ft)
ft

par(mfrow = c(1,3))
boxplot(tslaU1, main='Usual 1-day Returns')
boxplot(tsla1ret, main='1-day Returns after RSI = 30 Crossover')
boxplot(tslaNot1ret, main='1-day Returns after a Non-RSI = 30 Crossover')

par(mfrow = c(1,3))
boxplot(tslaU5, main='Usual 5-day Returns')
boxplot(tsla5ret, main='5-day Returns after RSI = 30 Crossover')
boxplot(tslaNot5ret, main='5-day Returns after a Non-RSI = 30 Crossover')

par(mfrow = c(1,3))
boxplot(tslaU10, main='Usual 10-day Returns')
boxplot(tsla10ret, main='10-day Returns after RSI = 30 Crossover')
boxplot(tslaNot10ret, main='10-day Returns after a Non-RSI = 30 Crossover')

par(mfrow = c(1,3))
boxplot(tslaU15, main='Usual 15-day Returns')
boxplot(tsla15ret, main='15-day Returns after RSI = 30 Crossover')
boxplot(tslaNot15ret, main='15-day Returns after a Non-RSI = 30 Crossover')

par(mfrow = c(1,3))
boxplot(tslaU20, main='Usual 20-day Returns')
boxplot(tsla20ret, main='20-day Returns after RSI = 30 Crossover')
boxplot(tslaNot20ret, main='20-day Returns after a Non-RSI = 30 Crossover')
par(mfrow=c(1,1))

# Compare boxplots.

par(mfrow = c(1,3))
boxplot(tslaU1, main='Usual 1-day Returns')
boxplot(tsla1ret, main='1-day Returns after RSIC')
boxplot(tslaNot1ret, main='1-day Returns after NRSIC')

boxplot(tslaU5, main='Usual 5-day Returns')
boxplot(tsla5ret, main='5-day Returns after RSIC')
boxplot(tslaNot5ret, main='5-day Returns after NRSIC')

boxplot(tslaU10, main='Usual 10-day Returns')
boxplot(tsla10ret, main='10-day Returns after RSIC')
boxplot(tslaNot10ret, main='10-day Returns after NRSIC')

boxplot(tslaU15, main='Usual 15-day Returns')
boxplot(tsla15ret, main='15-day Returns after RSIC')
boxplot(tslaNot15ret, main='15-day Returns after NRSIC')

boxplot(tslaU20, main='Usual 20-day Returns')
boxplot(tsla20ret, main='20-day Returns after RSIC')
boxplot(tslaNot20ret, main='20-day Returns after NRSIC')

# Compare histograms.

hist(tslaU1, main='Usual 1-day Returns',breaks=40)
hist(tsla1ret, main='1-day Returns after RSIC',breaks=10)
hist(tslaNot1ret, main='1-day Returns after NRSIC',breaks=40)

hist(tslaU5, main='Usual 5-day Returns',breaks=40)
hist(tsla5ret, main='5-day Returns after RSIC',breaks=10)
hist(tslaNot5ret, main='5-day Returns after NRSIC',breaks=40)

hist(tslaU10, main='Usual 10-day Returns',breaks=40)
hist(tsla10ret, main='10-day Returns after RSIC',breaks=10)
hist(tslaNot10ret, main='10-day Returns after NRSIC',breaks=40)

hist(tslaU15, main='Usual 15-day Returns',breaks=40)
hist(tsla15ret, main='15-day Returns after RSIC',breaks=10)
hist(tslaNot15ret, main='15-day Returns after NRSIC',breaks=40)

hist(tslaU20, main='Usual 20-day Returns',breaks=40)
hist(tsla20ret, main='20-day Returns after RSIC',breaks=10)
hist(tslaNot20ret, main='20-day Returns after NRSIC',breaks=40)

#Check the sample sizes and variances.
par(mfrow = c(1,3))
Stats <- c('Usual 1-day','1-day After RSIC','1-day After NRSIC')
Lengths <- c(length(tslaU1),length(tsla1ret),length(tslaNot1ret))
Variances <- c(var(tslaU1,na.rm=T),var(tsla1ret,na.rm=T), var(tslaNot1ret,na.rm=T))
flextable(data.frame(Stats,Lengths, Variances))

Stats <- c('Usual 5-day','5-day After RSIC','5-day After NRSIC')
Lengths <- c(length(tslaU5),length(tsla5ret),length(tslaNot5ret))
Variances <- c(var(tslaU5,na.rm=T),var(tsla5ret,na.rm=T), var(tslaNot5ret,na.rm=T))
flextable(data.frame(Stats,Lengths, Variances))

Stats <- c('Usual 10-day','10-day After RSIC','10-day After NRSIC')
Lengths <- c(length(tslaU10),length(tsla10ret),length(tslaNot10ret))
Variances <- c(var(tslaU10,na.rm=T),var(tsla10ret,na.rm=T), var(tslaNot10ret,na.rm=T))
flextable(data.frame(Stats,Lengths, Variances))

Stats <- c('Usual 15-day','15-day After RSIC','15-day After NRSIC')
Lengths <- c(length(tslaU15),length(tsla15ret),length(tslaNot15ret))
Variances <- c(var(tslaU15,na.rm=T),var(tsla15ret,na.rm=T), var(tslaNot15ret,na.rm=T))
flextable(data.frame(Stats,Lengths, Variances))

Stats <- c('Usual 20-day','20-day After RSIC','20-day After NRSIC')
Lengths <- c(length(tslaU20),length(tsla20ret),length(tslaNot20ret))
Variances <- c(var(tslaU20,na.rm=T),var(tsla20ret,na.rm=T), var(tslaNot20ret,na.rm=T))
flextable(data.frame(Stats,Lengths, Variances))

# Compare qq plots.

par(mfrow=c(1,3))
qqnorm(tslaU1)
qqline(tslaU1)
qqnorm(tsla1ret)
qqline(tsla1ret)
qqnorm(tslaNot1ret)
qqline(tslaNot1ret)

par(mfrow=c(1,3))
qqnorm(tslaU5)
qqline(tslaU5)
qqnorm(tsla5ret)
qqline(tsla5ret)
qqnorm(tslaNot5ret)
qqline(tslaNot5ret)

par(mfrow=c(1,3))
qqnorm(tslaU10)
qqline(tslaU10)
qqnorm(tsla10ret)
qqline(tsla10ret)
qqnorm(tslaNot10ret)
qqline(tslaNot10ret)

par(mfrow=c(1,3))
qqnorm(tslaU15)
qqline(tslaU15)
qqnorm(tsla15ret)
qqline(tsla15ret)
qqnorm(tslaNot15ret)
qqline(tslaNot15ret)

par(mfrow=c(1,3))
qqnorm(tslaU20)
qqline(tslaU20)
qqnorm(tsla20ret)
qqline(tsla20ret)
qqnorm(tslaNot20ret)
qqline(tslaNot20ret)
```

By looking at these plots, we start to see some pretty close to normal results with the 5 day, the 10 day, and the 15 day results. We also want to do a Shaprio test to test the normality of the data one last time!

``` {r shap, echo=FALSE}
shapiro <- c(0,0,0)
shapiro.test(tslaU1) 
shapiro.test(tsla1ret)
shapiro.test(tslaNot1ret)

shapiro.test(tslaU5) 
shapiro.test(tsla5ret) #normal
shapiro.test(tslaNot5ret)

shapiro.test(tslaU10) 
shapiro.test(tsla10ret) #normal
shapiro.test(tslaNot10ret)

shapiro.test(tslaU15) 
shapiro.test(tsla15ret) # between .05, .1, sort of normal, grounds for testing
shapiro.test(tslaNot15ret)

shapiro.test(tslaU20) 
shapiro.test(tsla20ret)
shapiro.test(tslaNot20ret)
```

From the above p-values, we have that the Tesla 5, 10, and 15 days after a RSI crossover appear to be normal. Now, we want to conduct Wilcoxon tests since our data has unequal variances and not normal. Even though the t-test can give accurate rejections or acceptions of the null hypothesis, this is usually for a large sample size. The RSI crossover set has 65 values. It depends on what large means. Nonetheless, the Wilcoxon test will tell us if the data is statistically different or the same. If we wanted to make a further inference about whether this statistical difference is good or bad, we would need to have two samples with equal variances.

``` {r ttest, echo=FALSE}

# Conduct wilcoxon tests.

# Quick note: If we want to show some sort of result, say the 
# stock prices increase after a RSIC below 30, we do need to have
# the extra assumption that the variances are equal. However,
# if we just want to state that the two sets of data are statistically
# different, we don't need equal variances.

wilcox.test(tslaU1, tsla1ret) #not equal to 0 
wilcox.test(tslaU1, tslaNot1ret) #equal to 0

wilcox.test(tslaU5, tsla5ret) #not equal to 0
wilcox.test(tslaU5, tslaNot5ret) #equal to 0

wilcox.test(tslaU10, tsla10ret) #not equal to 0 
wilcox.test(tslaU10, tslaNot10ret) #equal to 0

wilcox.test(tslaU15, tsla15ret) #not equal to 0
wilcox.test(tslaU15, tslaNot15ret) #equal to 0

wilcox.test(tslaU20, tsla20ret) #not equal to 0
wilcox.test(tslaU20, tslaNot20ret) #equal to 0

```

Judging from the series of Wilcoxon tests, we have a nice variety of data. For all of the post-RSI crossovers, we have a statistical difference in the data. The 20 day value is pushing the boundary if we used a .01 p-value threshold, however it is close enough to call it statistically different. In addition, the post Non-RSI crossovers are not different. This is to be expected because they are the closest to the actual set of data.

In conclusion, using the RSI value drop below 30 does give us a statistical difference from the usual price. Since we did not have equal variances, we cannot confirm if this is a positive or negative difference, but we can at least conclude that this indicator is worth looking into more, possibly in combination with the OBV, Simple Moving Averages, and more.

## OBV Calculation

To calculate the OBV, we follow a very simple process:

1. If today's closing price is higher than yesterday's closing price, then
$$ OBV_{current} = OBV_{previous} + Volume_{today}$$
2. If today's closing price is less than yesterday's closing price, then
$$ OBV_{current} = OBV_{previous} - Volume_{today}$$
3. If today's closing price equals yesterday's closing price, then
$$ OBV_{current} = OBV_{previous} $$
```{r obv, echo=FALSE}

OBV <- c()
tslaVol <- tsla[,7]

OBV[1] <- 0
for (i in 2:imax)
{
  OBV[i] <- 0
  if (tslaClose[i] > tslaClose[i-1])
  {
    OBV[i] <- OBV[i-1] + tslaVol[i]
  }
  else if (tslaClose[i] < tslaClose[i-1])
  {
    OBV[i] <- OBV[i-1] - tslaVol[i]
  }
  else if (tslaClose[i] == tslaClose[i-1])
  {
    OBV[i] <- OBV[i-1]
  }
}

val <- 100
plot(tslada[1:(imax-1)], tslaClose[1:(imax-1)],
     type ='l',
     main='Closing Price (Alltime)',
     xlab='Date',
     ylab='Price')
plot(tslada, OBV, type='l',
     main='On-Balance Volume Tsla (Alltime)',
     xlab='Date',
     ylab='OBV')

plot(tslada[1:(imax-val-1)], tslaClose[1:(imax-val-1)],
     type ='l',
     main='Closing Price (Zoomed In)',
     xlab='Date',
     ylab='Price')
plot(tslada[(imax-val-1):(imax-1)], OBV[(imax-val-1):(imax-1)], type='l',
     main='On-Balance Volume Tsla (Zoomed In)',
     xlab='Date',
     ylab='OBV')

```

The OBV tallies up and down volume, creating a smooth indicator line to predict when major moves might occur based on changes in relative trading volume. Investors can use the OBV to provide many key predictions, such as a bullish divergence predicting the price will break resistance or a bearish divergence predicting a rally will stall or reverse.

## Attempting Rating Methods between Stocks

This is probably the most interesting part of our data! We want to know how a certain stocks performance compares with another stocks. We as investors want to make money! Say we have a list of 500 stocks, we've analyzed them from a statistical perspective, yet we don't if one stock is betteer than the other. Why don't we use our rating algorithms and linear algebra?

There are three primary methods we have learned to implement: Massey's method, Colley's method, and Markov's method. Traditionally, these methods look at games between two teams, and we can easily calculate a point differential, a total yards differential, or a winning percentage. 

What exactly is a "win" when we talk about stocks? There are a few ways to think about this:

1. We compare a stock against itself. We count every day that a stock goes up from the day before it as a win.

2. We compare the stock against other stocks. We count every day that stock A goes up and stock B goes down as a win for stock A, and the opposite would be a win for stock B. If they both don't increase or decrease, we will count it as a tie.

Though we are not looking at point differentials, some ways to maybe explore this for stocks would be:

1. Closing Price
2. P/E ratio
3. Outstanding Shares
4. Volume
5. Any technical indicator

This might get suspect since stock prices and such differs greatly between companies. For example, Sunworks (SUNW) is worth approximately \$3.78 per share while Google (GOOG/GOOGL) is worth \$2960.03 per share. A point differential between these two doesn't exactly make sense. A great amount of stocks fall far below Google's share price.

## Calculating Win Percentages

Numbers 1 and 2 from above were used. The data was truncated to include the most recent data with a size of the lowest maximum data. We analyzed 5 stocks, Tesla (TSLA), Facebook (FB), Microsoft (MSFT), Sunworks, an Google, and Facebook had the lowest amount of data at 2408 values.

A quick look at each of the stock's closing prices:

``` {r winp1, echo = FALSE}

tsla <- read.csv("./TSLA.csv")
fb <- read.csv("./FB.csv")
msft <- read.csv("./MSFT.csv")
sunw <- read.csv("./SUNW.csv")
goog <- read.csv("./GOOGL.csv")

tsla$Date <- as.Date(tsla$Date, format="%Y-%m-%d")
fb$Date <- as.Date(fb$Date, format="%Y-%m-%d")
msft$Date <- as.Date(msft$Date, format="%Y-%m-%d")
sunw$Date <- as.Date(sunw$Date, format="%Y-%m-%d")
goog$Date <- as.Date(goog$Date, format="%Y-%m-%d")

min_data <- min(nrow(tsla),nrow(fb),nrow(msft),nrow(sunw),nrow(goog))

tsla1 <- tsla[(nrow(tsla) - min_data + 1):nrow(tsla),]
fb1 <- fb
msft1 <- msft[(nrow(msft) - min_data + 1):nrow(msft),]
sunw1 <- sunw[(nrow(sunw) - min_data + 1):nrow(sunw),]
goog1 <- goog[(nrow(goog) - min_data + 1):nrow(goog),]

#Select out returns and dates

tslaClose <- tsla1[,5]
tslaDates <- tsla1[,1]

fbClose <- fb1[,5]
fbDates <- fb1[,1]

msftClose <- msft1[,5]
msftDates <- msft1[,1]

sunwClose <- sunw1[,5]
sunwDates <- sunw1[,1]

googClose <- goog1[,5]
googDates <- goog1[,1]

#Plot the data we are working with

plot(tslaDates, tslaClose, 
     type='l',
     main="TSLA Closing Prices",
     xlab="Date",
     ylab="Closing Price",
     col='black')
plot(fbDates, fbClose, 
     type='l',
     main="FB Closing Prices",
     xlab="Date",
     ylab="Closing Price",
     col='black')
plot(msftDates, msftClose, 
     type='l',
     main="MSFT Closing Prices",
     xlab="Date",
     ylab="Closing Price",
     col='black')
plot(sunwDates, sunwClose, 
     type='l',
     main="SUNW Closing Prices",
     xlab="Date",
     ylab="Closing Price",
     col='black')
plot(googDates, googClose, 
     type='l',
     main="GOOG Closing Prices",
     xlab="Date",
     ylab="Closing Price",
     col='black')
```

Now, lets look at our first computation of the winning percentages:

``` {r wp1, echo=FALSE}

WP <- c(0,0,0,0,0)
wins <- 0

for (i in 2:min_data)
{
  if (tslaClose[i-1] < tslaClose[i])
  {
    wins <- wins + 1
  }
}
WP[1] <- wins/min_data

wins <- 0

for (i in 2:min_data)
{
  if (fbClose[i-1] < fbClose[i])
  {
    wins <- wins + 1
  }
}
WP[2] <- wins/min_data

wins <- 0

for (i in 2:min_data)
{
  if (msftClose[i-1] < msftClose[i])
  {
    wins <- wins + 1
  }
}
WP[3] <- wins/min_data

wins <- 0

for (i in 2:min_data)
{
  if (sunwClose[i-1] < sunwClose[i])
  {
    wins <- wins + 1
  }
}
WP[4] <- wins/min_data

wins <- 0

for (i in 2:min_data)
{
  if (googClose[i-1] < googClose[i])
  {
    wins <- wins + 1
  }
}
WP[5] <- wins/min_data

labels <- c('GOOG','MSFT','FB','TSLA','SUNW')
rankings <- c(1,2,3,4,5)

WP <- WP[order(WP, decreasing=T)]
WP <- as.matrix(WP)
colnames(WP) <- 'Ratings'
rankings <- row(WP)
colnames(rankings) <- 'Ranking'
results <- cbind(WP, rankings)
rownames(results) <-labels
print(results)
```

We see that the first four stocks are relatively close, and Sunworks is very low compared to these ones. Sunworks is a very different company compared to the other four. Looking at this win percentage alone can give us a little insight into how well a stock is performing.

## Conclusions

We have calculated a lot of interesting data. We have calculated the RSI, the OBV, and a basic win percentage of the 5 stocks listed above. We also have performed a technical analysis on TSLA, and confirmed that using a RSI value falling below 30 as a buy signal does result in a statistical difference, and thus we should use more indicators and analysis to confirm if this is an appropriate and profitable buy signal. 

In terms of our ranking methods, we didn't quite get to the methods we wanted to try. It would have been really nice to see how we can translate sports ranking methods to stock data. The Colley equations were all set up to go, but project after project stacked up and time just ran out. 

In terms of next steps, we need to define a 'game' against two stocks, and then determine the number of wins and losses to formulate the Colley method.

